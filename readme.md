# RL\_2MMS50

A collection of reinforcementâ€‘learning agents (tabular & deep) implemented for **Blackjack** and **Atari** games. This repository provides scripts to train and evaluate various agents:

- **Tabular agents** for Blackjack: Qâ€‘learning, SARSA, TD(0).
- **Deep agents** for Atari: DQN, Deep SARSA, Deep TD(0).

---

## ðŸš€ Quickstart

1. **Clone** this repository and `cd` into it:

   ```bat
   git clone <repo_url>
   cd RL_2MMS50
   ```

2. **Optional:** create and activate a virtual environment:

   ```bat
   python -m venv .venv
   .\.venv\Scripts\activate.bat
   python -m pip install --upgrade pip setuptools wheel
   ```

3. **Install core Python dependencies**:

   ```bat
   pip install -r requirements.txt
   ```

4. **Install GPUâ€‘enabled PyTorch** (if available):

   ```bat
   pip install --extra-index-url https://download.pytorch.org/whl/cu121 \
       torch==2.5.1+cu121 \
       torchvision==0.20.1+cu121 \
       torchaudio==2.5.1+cu121
   ```

5. **Accept Atari ROM license** (required for Gymnasium/ALE):

   ```bat
   python -m autorom --accept-license
   ```

6. **Run all training & evaluation** via batch script:

   ```bat
   .\run_all.bat
   ```

   This executes all train & evaluate modules in sequence.

---

## ðŸ“‚ Directory Structure

```
RL_2MMS50/
â”œâ”€â”€ agents/                # Agent implementations (tabular & deep)
â”‚   â”œâ”€â”€ q_learning_agent.py
â”‚   â”œâ”€â”€ sarsa_agent.py
â”‚   â”œâ”€â”€ td0_agent.py
â”‚   â”œâ”€â”€ dqn_agent.py
â”‚   â”œâ”€â”€ deep_sarsa_agent.py
â”‚   â””â”€â”€ deep_td0_agent.py
â”œâ”€â”€ configs/               # Hyperparameter configs
â”‚   â”œâ”€â”€ grid_configs.py
â”‚   â””â”€â”€ atari_configs.py
â”œâ”€â”€ environments/          # Gym wrappers
â”‚   â”œâ”€â”€ blackjack_env.py
â”‚   â””â”€â”€ atari_env.py
â”œâ”€â”€ train_logic/           # Shared training loops
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ dqn_trainer.py
â”‚   â”œâ”€â”€ deep_sarsa_trainer.py
â”‚   â”œâ”€â”€ deep_td0_trainer.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train/                 # `python -m train.*` entry scripts
â”‚   â”œâ”€â”€ train_q_learning.py
â”‚   â”œâ”€â”€ train_sarsa.py
â”‚   â”œâ”€â”€ train_td0.py
â”‚   â”œâ”€â”€ train_dqn.py
â”‚   â”œâ”€â”€ train_deep_sarsa.py
â”‚   â””â”€â”€ train_deep_td0.py
â”œâ”€â”€ evaluate/              # `python -m evaluate.*` entry scripts
â”‚   â”œâ”€â”€ evaluate_q_learning.py
â”‚   â”œâ”€â”€ evaluate_sarsa.py
â”‚   â”œâ”€â”€ evaluate_td0.py
â”‚   â”œâ”€â”€ evaluate_dqn.py
â”‚   â”œâ”€â”€ evaluate_deep_sarsa.py
â”‚   â””â”€â”€ evaluate_deep_td0.py
â”œâ”€â”€ models/                # Trained models by category
â”‚   â”œâ”€â”€ models_q_learning/
â”‚   â”œâ”€â”€ models_sarsa/
â”‚   â”œâ”€â”€ models_td0/
â”‚   â”œâ”€â”€ models_dqn/
â”‚   â”œâ”€â”€ models_deep_sarsa/
â”‚   â””â”€â”€ models_deep_td0/
â”œâ”€â”€ results/               # Plots & evaluation outputs
â”‚   â”œâ”€â”€ results_q_learning/
â”‚   â”œâ”€â”€ results_sarsa/
â”‚   â”œâ”€â”€ results_td0/
â”‚   â”œâ”€â”€ results_dqn/
â”‚   â”œâ”€â”€ results_deep_sarsa/
â”‚   â””â”€â”€ results_deep_td0/
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ run_all.bat            # Batch script to run all
â””â”€â”€ README.md              # This file
```

---

## ðŸ“ˆ Training & Evaluation

### Atari agents (single-seed)

All Atari training scripts default to seed `0` and use an explicit `--env-id`:

```bat
python -m train.train_<agent> \
    --env-id ALE/Boxing-v5 --episodes 100 [--lr 1e-4] [--gamma 0.99] [--render]
```

- **Saved model** â†’ `models/models_<agent>/<agent>_<env_id>_seed0.pth`
- **Rewards plot** â†’ `results/results_<agent>/<agent>_<env_id>_<episodes>eps_seed0.png`

Batch evaluation over all Atari models:

```bat
python -m evaluate.evaluate_<agent> --env-id ALE/Boxing-v5 --trials 500
```

This will scan `models/models_<agent>/`, evaluate each `.pth`, and write `<model_basename>_winrate.txt` in `results/results_<agent>/`.

### Blackjack agents (multi-seed)

Blackjack scripts run over multiple seeds and hyperparameters:

```bat
python -m train.train_<agent> --episodes 10000 --num-seeds 5 [--alpha 0.1] [--gamma 0.9]
```

- Only **seedÂ 0** model is saved per `(Î±,Î³)`:
  - Q-table â†’ `models/models_<agent>/<agent>_alpha<Î±>_gamma<Î³>_seed0.pkl`
- **Win-rate curve** (across seeds) â†’ `results/results_<agent>/<agent>_winrate_<episodes>eps_<seeds>seeds_a<Î±>_g<Î³>.png`

Batch evaluation over all Blackjack models:

```bat
python -m evaluate.evaluate_<agent> --trials 1000
```

Automatically scans `models/models_<agent>/`, evaluates each `.pkl`, and writes `<model_basename>_winrate.txt` into `results/results_<agent>/`.

---

Use `-h` on any script to see full argument list and defaults.

